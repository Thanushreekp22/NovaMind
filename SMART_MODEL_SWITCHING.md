# ü§ñ Smart Model Switching - NovaMind

## Intelligent Vision Model Selection

Your NovaMind AI now **intelligently optimizes** vision processing based on what you ask!

---

## Important Update

**Note:** The 11B vision model has been decommissioned by Groq. All vision requests now use the **90B model**, but the smart system still optimizes token allocation and temperature settings based on your query complexity.

### **Automatic Optimization** üéØ

The system analyzes your question and adjusts:
- ÔøΩ **Simple queries** ‚Üí Standard tokens (1500)
- üéØ **Detailed analysis** ‚Üí Extended tokens (2000)

---

## Model Selection Logic

### **Uses 90B (High Quality) Model When:**

‚úÖ **Detailed Analysis Requested**
- "Describe this image **in detail**"
- "Give me a **detailed** description"
- "**Analyze** this thoroughly"

‚úÖ **Text Reading (OCR)**
- "**Read** the text in this image"
- "What does the **writing** say?"
- "**Transcribe** the text"
- "**Extract** all text"

‚úÖ **Counting/Precision Tasks**
- "**Count** all the people"
- "**How many** objects are there?"
- "**List all** the items"
- "**Identify** everything you see"

‚úÖ **Professional/Technical Use**
- "**Professional** analysis"
- "**Medical** diagnosis"
- "**Technical** specifications"
- "**Scientific** description"

‚úÖ **Long/Complex Questions**
- Questions longer than 100 characters
- Multiple questions in one prompt

### **Uses 11B (Fast) Model When:**

‚ö° **Quick Questions**
- "What is this?"
- "What's in this image?"
- "Can you see a cat?"
- "Is there a car?"

‚ö° **Simple Descriptions**
- "**Briefly** describe this"
- "**Quick** summary"
- "**Just** tell me what you see"

‚ö° **General Queries**
- "What colors are there?"
- "Is this indoors or outdoors?"
- "What's the main object?"

---

## Examples

### Example 1: Fast Model (11B)
**User:** "What's in this image?"
**System:** Uses 11B (Fast) - reason: general query
**Response Time:** ~1-2 seconds

### Example 2: Quality Model (90B)
**User:** "Read all the text in this image carefully"
**System:** Uses 90B (High Quality) - reason: OCR requested
**Response Time:** ~3-5 seconds

### Example 3: Quality Model (90B)
**User:** "Analyze this image in detail and describe everything you see"
**System:** Uses 90B (High Quality) - reason: detailed analysis requested
**Response Time:** ~3-5 seconds

### Example 4: Fast Model (11B)
**User:** "Is there a dog?"
**System:** Uses 11B (Fast) - reason: simple query
**Response Time:** ~1-2 seconds

---

## Keyword Triggers

### **High Quality Model Keywords:**
```
detail, detailed, describe in detail, thoroughly
analyze, analysis, professional, accurately
read, text, ocr, words, letters, writing
count, how many, identify all, list all
medical, diagnosis, technical, scientific
transcribe, extract, recognize text
carefully, precisely, exact, specific
```

### **Fast Model Keywords:**
```
quick, briefly, simple, just
what is, is there, can you see
show, find, any, general
```

---

## Testing the Smart Selection

### Test 1: Simple Query
```
Upload an image
Type: "What is this?"
Expected: 11B Fast Model ‚ö°
```

### Test 2: OCR Request
```
Upload an image with text
Type: "Read the text"
Expected: 90B Quality Model üéØ
```

### Test 3: Detailed Analysis
```
Upload any image
Type: "Analyze this image in detail"
Expected: 90B Quality Model üéØ
```

### Test 4: Counting
```
Upload an image with multiple objects
Type: "Count all the cars"
Expected: 90B Quality Model üéØ
```

---

## Benefits

### ‚úÖ **Automatic Optimization**
- No need to manually choose models
- Best model for each situation
- Optimal speed/quality balance

### ‚úÖ **Cost Efficient**
- Uses fast model when possible
- Saves processing time
- Better resource utilization

### ‚úÖ **Better User Experience**
- Quick responses for simple questions
- Detailed analysis when needed
- Smart and adaptive

---

## Customization

Want to modify the logic? Edit `Backend/utils/openai.js`:

### **Add Your Own Keywords:**
```javascript
const HIGH_QUALITY_KEYWORDS = [
    'detail', 'analyze', 'read',
    // Add your keywords here:
    'important', 'critical', 'urgent'
];
```

### **Adjust Thresholds:**
```javascript
// Change from 100 to your preferred length
if (lowerMessage.length > 100) {
    // Use high quality model
}
```

### **Force a Specific Model:**
```javascript
// Always use 90B for images
return {
    model: CONFIG.HIGH_QUALITY_MODEL,
    maxTokens: CONFIG.DETAILED_MAX_TOKENS,
    reason: 'forced high quality'
};
```

---

## Manual Override (If Needed)

If you want to **force** a specific model, modify the config:

### Force Fast Model (11B) Always:
```javascript
const selectVisionModel = (userMessage) => {
    return {
        model: CONFIG.DEFAULT_VISION_MODEL,
        maxTokens: CONFIG.VISION_MAX_TOKENS,
        reason: 'forced fast model'
    };
};
```

### Force Quality Model (90B) Always:
```javascript
const selectVisionModel = (userMessage) => {
    return {
        model: CONFIG.HIGH_QUALITY_MODEL,
        maxTokens: CONFIG.DETAILED_MAX_TOKENS,
        reason: 'forced quality model'
    };
};
```

---

## Monitoring

Check your terminal to see which model is being used:

```bash
üñºÔ∏è  Vision Model: 11B (Fast) - Reason: general query
```

or

```bash
üñºÔ∏è  Vision Model: 90B (High Quality) - Reason: detailed analysis requested
```

---

## Performance Impact

| Scenario | Model Used | Speed | Quality |
|----------|-----------|-------|---------|
| "What is this?" | 11B | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| "Read the text" | 90B | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| "Describe in detail" | 90B | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| "Is there a car?" | 11B | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |

---

## Summary

‚úÖ **Smart Selection** - Automatically chooses best model
‚úÖ **Keyword-Based** - Analyzes your question
‚úÖ **Optimized** - Speed when possible, quality when needed
‚úÖ **Transparent** - Shows which model is used
‚úÖ **Customizable** - Easy to modify logic

Your AI now thinks before choosing which brain to use! üß†‚ö°

---

**Last Updated**: November 14, 2025
